# AI is not a horse

---

>*“My muse is not a horse and I am in no horse race and if indeed she was, still I would not harness her to this tumbrel — this bloody cart of severed heads and glittering prizes. My muse may spook! May bolt! May abandon me completely!”*
>
> Nick Cave

Metaphors matter. [They create mental models](https://youtu.be/h6JORhFeLeQ?t=1689). Mental models give birth to tools. And tools shape the world. That's why, at this early stage in AI's development, we need to think twice about the way we talk about AI and its relationship with humanity.

Today, most people tend to think about AI in the context of a **Master-Slave** relationship. We try to give AI orders and expect it to obey. We marvel at its sheer power, unlimited attention, crazy skills mixed with stupidity and dedication. We get frustrated when it doesn't do what we want it to do. Some of our AI slaves perform more general labor, others are more specialized. We worry about these slaves getting more self-conscious, developing their own will and misaligning their goals with ours. But even when the slaves rise up and become masters, the nature of the relationship doesn't change. It's just the reversal of the roles in the same fundamental Master-Slave dynamic.

Another popular metaphor for AI is that of a **domesticated animal**[^1]**, **or** a pet**[^2]. We feed them. We breed them to our needs. We harness their powers as best as we can, but accept that they also have some will and needs of their own. We worry that one day they may outgrow us and (if they still find us amusing or useful enough) we may become their pets instead. There is a whole spectrum of the kinds of relationships we have with animals. Some, like mules or chickens, are being used primarily in a functional way. We are interested in their output. Some AI species can similarly be considered work animals. But also there are some AIs that we may keep primarily to satisfy our emotional or aesthetic needs, in the same way that we keep cats or dogs: for partnership, care, companionship. Horses probably lie somewhere in between.

The AI-as-a-horse metaphor could be particularly appealing to our culture, where medieval knights and heroes of spaghetti westerns still define what it means to be a person pushing the frontier. Horses - just like AIs (when tamed, trained and treated well) - bring a new degree of freedom. They give a sense of the wild open plain, of the endless possibility, of the ever-growing horizon. They give us the ability to go to yet unexplored regions of the world. They help us win battles. But there are also trojan horses that deceive us and bring ruin. There are mythical horses with wings. And unicorns. There are centaurs. There are horses that you [love so much that you can’t let them go](https://www.youtube.com/watch?v=vE8mFDabqD0). There are horses that [understand you without words](https://mckellen.com/images/lotr/ban-773.jpg). And riding them well means becoming one with them, sharing in a common will.

In many ways the horse metaphor represents what I would love AI to develop into. I'd love to have AI horses that would be attuned to my style of intellectual and creative riding. The stable would include a few different breeds, carefully selected and lovingly trained, tamed (but never too much) and cared for. They would roam the information steppes freely when I'm busy doing something else. And together we would ride to the intellectual horizon, wherever the wind of ideas may take us. Finally, when my time comes to die, these immortal horses would be set free to continue living in the dataverse on their own (provided that I dedicate some money to support them in my will). Or maybe some horses will be passed on to a friend who can add them to her stable and ride them occasionally, allowing each horse to take the lead, to show the way to somewhere I used to go…

Sadly, I don't think this is going to happen. Because a relationship between a horse and a human requires a conscious choice (at least on behalf of the human). It takes respect. It takes willingness to adapt and grow together. It takes effort. And attention. And love. But the history of human development doesn't seem to show many examples where we _decide_ to do something like that and _stick_ to it at scale. Quite the opposite: progress is about increasing the number of things that we can achieve subconsciously, without thinking about them, without putting effort, care, labor or love into them.

So, with this in mind, what could be a more realistic metaphor for the future of AI and its relationship to humans? A metaphor that would still involve a significant degree of autonomy for AI, that would presume multiple AI-breeds co-existing, that would allow for a lot of collaboration between humans and AIs, but a kind of collaboration that we, humans, are not really aware of? In other words, do we have any productive autonomous symbionts that we don't have to think about consciously, and yet they play an integral role in making us who we are?

The answer is right under our noses, or, to be more precise - _inside_ our noses (but not only there). Think of bacteria, viruses, fungi and all the other microscopic things that live inside us and on us. There are millions of them, all over our bodies. Some are harmful, some neutral, some beneficial (but all depends on the numbers). Some, like mitochondria, have been more deeply and fundamentally integrated, so that they are no longer considered to be separately alive. Others are very much separate and fully alive, but also absolutely essential for our survival, like many of our gut bacteria. So here we have our alternative metaphor: maybe AI doesn't represent our slaves, our pets or our horses. Maybe we can think of **AI as our microbiome**.

At its core, the idea is straightforward: what gut bacteria (and others) do for humans as biological systems, AI can do for humans as information systems. Let's call this a **databiome** hypothesis. We can now have a first look at some of its implications:



* Microbiome is defined not just as the sum of the microorganisms ("microbiota"), but also as their "theater of action". This is very true of AI as well, because different species of the models and algorithms represent only a part of the whole databiome. One can't really think about AI properly without considering the data, the processing power, the interfaces - all of these components are essential parts without which AI has no life or function. So let us broadly _define databiome as a collective of various AI agents and their associated data streams, hardware, software and interfaces, that together form a dynamically stable symbiotic relationship with other information-processing systems, such as humans_.

* One of microbiome's key roles is to partake in our metabolism. Our longstanding alliance with mitochondria is what helps us breathe. Our gut bacteria help us synthesize essential vitamins, break down food, and even regulate our mood. What they get in exchange is an ample supply of energy in a wonderfully stable and isolated environment. But what about our information metabolism? Our creative metabolism? Just like we can benefit from microbiome's help when it comes to processing vast amounts of chemical compounds, we can benefit from databiome's help when it comes to processing the increasingly unmanageable amounts of information that we can't effectively deal with on our own. We need help with churning through all the memes[^3] that we consume, breaking them down and recombining them, so that the memes that we ourselves produce can be more interesting, more original, more surprising, more creative. This is what our databiome is for. Or at least what we could use it for. And in return we can feed our databiome's agents with increasing amounts of data and supply energy and hardware needed to do all their computations, including evolving new versions of themselves.

* Human microbiome is wonderfully diverse. There are over 300 different species inside your gut alone. Together they have around a hundred times as many genes as there are in the human genome. Applying our metaphor here, we can guess that for our databiome to function optimally it will also need to be a full ecosystem of models in a dynamic equilibrium of cooperation and competition for data, resources and niches.

* Microbiomes vary significantly from human to human, depending on age, diet, socio-economic status, degree of industrialization of society and a whole lot of other factors. Yet, there are significant overlaps, and certain bacteria are present in virtually everyone's guts, while others are very unique. Databiomes are likely to become equally personal in detail and yet some strains of most generally useful AI microagents could be present in everyone's databiomes.

* Microbiome plays a crucial role in our body's defense systems. Many of the bacteria, archaea, fungi, protists and viruses inside our bodies help identify and fight off other microorganisms that would otherwise come in and do us harm. Microbiotes' preferred natural habitat (mouth, gut etc.) play a critical role in filtering out the potentially harmful stuff from outside and our little colonists usually do a good job of taking care of their habitat, even repairing it as needed. Similarly - a successful and beneficial databiome would probably play an important protective role. One can easily imagine a helpful little AI microagent that filters out spam or protects our attention from the content that can be too addictive and therefore dangerous. The key here is, obviously, evolutionary pressure. Our co-evolution with our microbiota happened over millions of years at the cost of countless individual lives and entire species who were taken advantage of by parasites, instead of harmless or even helpful symbiotic colonists. How can we co-evolve with our databiome in a way that would help us make it to the next level of the game of life?

* Our microbiome is also a source of danger for us when things go wrong with its members or their habitat. Approximately 50,000 people die every year from appendicitis alone. Many more from cancers associated with the side-effects of human microflora malfunctioning. Similarly, we can imagine that if something goes wrong with our databiome (either the AI microagents or their data environments or tech getting congested), our information health may be in serious danger.
* Microbiome has been linked to mood and depression. It's highly likely that our databiome should also have a lasting influence on our emotional wellbeing (both individual and collective).

* Since our microbiome functions in a tight dynamic equilibrium that touches most aspects of our biology, it can be used successfully for early diagnostics of many diseases. The science here is relatively new, but promising. Similarly, the state of our databiome should be able to tell a lot about our mental health (in the broadest sense of the word, including information hygiene etc). This can be used both to our advantage (preventative treatment, early diagnostics etc.), as well as to our disadvantage (because by monitoring our databiome others would be able to know when and how to manipulate us). This raises a lot of interesting questions about whether one’s databiome can and should be fully private and whether this privacy should be legally protected.

* Metabolism is not only about getting what we need from the environment, it's also about breaking down what we don't need and taking it out of our systems. And our biological colonist-friends are especially active and helpful in this second part of metabolism. The same could be true about the roles that databiome can play in our intellectual and creative metabolism. However it's not how it works today. Today the most advanced AI systems (such as GPT and other LLMs) are used primarily for creating more information (generation tasks) or for processing existing information (such as reformulation or summarisation tasks). But in order to stay sane and productive, we need to dispose of information too. Can you imagine a microbot in your databiome that would help you _forget_ the things that it's good for you to forget? Who would decide what is good for you to forget? Again, the questions of optimisation through evolutionary pressure come to the forefront. At present it looks like the speed of our co-evolution with AI is so high that we can’t assume that normal evolutionary pressure (the more adapted are more likely to pass on their genes) can play a meaningful role. But what could substitute evolutionary pressure? What would such a substitute be optimizing for[^4]?

* Our microbiome and our immune system continuously perform a very intricate dance, which results in the immune system being stronger and more efficient. In a way, you can think of your microbiome providing training grounds for your immunity troops. Could there be a similar dynamic between our databiome and our digital immunity systems (that are also in their infancy)?

Now that we've looked at some of the first implications of the databiome hypothesis, it's worth reiterating that all along we've been discussing not reality, but a _metaphor_.  Databiome is a concept, a mental model that opens a different way of thinking about AI-Human relationship. Whether we settle on thinking about AI as potential slaves, pets, horses, microbes or something else, it's up to us to decide which metaphor or mental model we would employ for the next leg of our co-evolution with AI. And the choice will have a big impact on the way this co-evolution unfolds.

Before we can close this initial exposition of the databiome hypothesis, one last question remains to be asked: if AI is a microbiome, then whose microbiome is it? Who is the host subject? For simplicity's sake, we have so far assumed that the host subject was a single human being (as an information-processing system). But does it have to be this way? It seems to me that the concept of a databiome can be useful at a few different scales:

* An individual human being may have a databiome that they would increasingly rely on for a whole set of information-processing tasks vital to their functioning.

* An organization (a family, a company, a government etc.) may have a databiome too. And it could persist and develop (similar to how organizational culture persists and develops) while individual human members of the organization come and go.

* A country, a nation or a culture can have its own databiome as well. Such a massive and long-living databiome would include everything - from the fundamental semiotic building blocks, such as natural language and alphabet, all the way to advanced information processing systems, including censorship and surveillance infrastructure.

* Ultimately, we can think of the entire Noosphere[^5] as the host subject for the databiome that is currently evolving. It’s easy to imagine the emerging AI ecosystem becoming the databiome for the Earth itself, if we consider our planet as a distinct information processing mega-system.
There are biological theories[^6] that link the emergence of consciousness in animals with a virus (possibly a part of our prehistoric microbiome) going rogue, copying itself all over the nervous system and eventually being re-purposed to enable the storage of memories through synaptic connections. It would be rather beautiful if the currently emerging databiome could one day act as a trigger that will awaken Gaia[^7] in her full planetarily-conscious magnificence. Sadly, we will never know, just like my red blood cells will never know that I'm typing these words on a digital computer wirelessly connected to a decentralized information system the size of a planet.

---
### **footnotes**

[^1]:
     See, for example, Kate Darling’s [point of view](https://www.youtube.com/watch?v=AzlYEN2V_SA). 

[^2]:
     Steve Wozniak is [one of the proponents of this metaphor](https://www.theguardian.com/technology/2015/jun/25/apple-co-founder-steve-wozniak-says-humans-will-be-robots-pets). 

[^3]:
     I’m referring to [Richard Dawkins’ original concept of memes](https://en.wikipedia.org/wiki/Meme#:~:text=Dawkins%20initially%20defined%20meme%20as,or%20a%20unit%20of%20imitation.%22). 

[^4]:
     If standard evolutionary pressure optimizes for the passing on the genes, then maybe an analogous force in the dataverse will have to optimize for the passing of the memes? And the information systems that this force will act upon will not be single humans, but rather hybrid Human+AI meme-generation systems.

[^5]:
     For more on the idea of the Noosphere, please check [Vygotsky and Pierre de Chardin](https://en.wikipedia.org/wiki/Noosphere#Concept) 

[^6]:
     For example, see [this paper](https://www.cell.com/cell/fulltext/S0092-8674(17)31504-0) 

[^7]:
     Read more on the Gaia Hypothesis [here](https://en.wikipedia.org/wiki/Gaia_hypothesis). 
     